{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60ab515",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b9193c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: peft in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: accelerate in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (0.45.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from datasets) (3.11.18)\n",
      "Requirement already satisfied: psutil in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from peft) (2.5.1+cu121)\n",
      "Requirement already satisfied: networkx in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from torch>=1.13.0->peft) (80.1.0)\n",
      "Collecting sympy==1.13.1 (from torch>=1.13.0->peft)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.2/6.2 MB 42.3 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ympy (c:\\Users\\nelld\\Desktop\\N7\\2SNIA\\llamaenv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (c:\\Users\\nelld\\Desktop\\N7\\2SNIA\\llamaenv\\Lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 32] Le processus ne peut pas acc√©der au fichier car ce fichier est utilis√© par un autre processus: 'c:\\\\users\\\\nelld\\\\desktop\\\\n7\\\\2snia\\\\llamaenv\\\\lib\\\\site-packages\\\\sympy\\\\polys\\\\solvers.py'\n",
      "Check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unsloth in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (2025.4.5)\n",
      "Requirement already satisfied: unsloth_zoo>=2025.4.4 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (2025.4.4)\n",
      "Requirement already satisfied: torch>=2.4.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (2.5.1+cu121)\n",
      "Requirement already satisfied: xformers>=0.0.27.post2 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (0.0.30)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (0.45.5)\n",
      "Requirement already satisfied: triton-windows in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (3.3.0.post19)\n",
      "Requirement already satisfied: packaging in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (25.0)\n",
      "Requirement already satisfied: tyro in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (0.9.19)\n",
      "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (4.51.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (3.5.1)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (0.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (7.0.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (2.2.5)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (1.6.0)\n",
      "Requirement already satisfied: trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (0.15.2)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (0.15.2)\n",
      "Requirement already satisfied: protobuf<4.0.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (3.20.3)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (0.30.2)\n",
      "Requirement already satisfied: hf_transfer in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (0.33.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth) (0.20.1+cu121)\n",
      "Requirement already satisfied: rich in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (14.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (3.11.18)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets>=2.16.0->unsloth) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from huggingface_hub->unsloth) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2025.4.26)\n",
      "Requirement already satisfied: networkx in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from torch>=2.4.0->unsloth) (80.1.0)\n",
      "Collecting sympy==1.13.1 (from torch>=2.4.0->unsloth)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from tqdm->unsloth) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.1)\n",
      "Requirement already satisfied: cut_cross_entropy in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth_zoo>=2025.4.4->unsloth) (25.1.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth_zoo>=2025.4.4->unsloth) (11.2.1)\n",
      "Requirement already satisfied: msgspec in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from unsloth_zoo>=2025.4.4->unsloth) (0.19.0)\n",
      "Requirement already satisfied: hf-xet>=0.1.4 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from huggingface_hub[hf_xet]>=0.30.0->unsloth_zoo>=2025.4.4->unsloth) (1.1.0)\n",
      "Collecting torch>=2.4.0 (from unsloth)\n",
      "  Using cached torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from diffusers->unsloth) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from pandas->datasets>=2.16.0->unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from pandas->datasets>=2.16.0->unsloth) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from unsloth)\n",
      "  Using cached torchvision-0.22.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from tyro->unsloth) (0.16)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from tyro->unsloth) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in c:\\users\\nelld\\desktop\\n7\\2snia\\llamaenv\\lib\\site-packages (from tyro->unsloth) (4.4.2)\n",
      "Using cached torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached torchvision-0.22.0-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "Installing collected packages: sympy, torch, torchvision\n",
      "\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "   ---------------------------------------- 0/3 [sympy]\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ympy (c:\\Users\\nelld\\Desktop\\N7\\2SNIA\\llamaenv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (c:\\Users\\nelld\\Desktop\\N7\\2SNIA\\llamaenv\\Lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 32] Le processus ne peut pas acc√©der au fichier car ce fichier est utilis√© par un autre processus: 'c:\\\\Users\\\\nelld\\\\Desktop\\\\N7\\\\2SNIA\\\\llamaenv\\\\Lib\\\\site-packages\\\\sympy\\\\solvers\\\\inequalities.py'\n",
      "Check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets peft accelerate bitsandbytes\n",
    "%pip install unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a143269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nelld\\Desktop\\N7\\2SNIA\\llamaenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "model_name = \"bigcode/starcoder2-3b\"\n",
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,).to(device)\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id # for LoRA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6865405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset, assuming jsonl format with \"text\" key\n",
    "dataset = load_dataset(\"json\", data_files={\"train\": \"elm_code_units.jsonl\"})\n",
    "\n",
    "# Tokenize function for causal LM\n",
    "def tokenize_function(examples):\n",
    "    encoding = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "    )\n",
    "    encoding[\"labels\"] = encoding[\"input_ids\"].copy()\n",
    "    return encoding\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05c301c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "per_device_train_batch_size = 1\n",
    "gradient_accumulation_steps = 8  # Increase to keep the same effective batch size\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Adjust for StarCoder2\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135deb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./starcoder_elm_finetuned\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    learning_rate=3e-4,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65777abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # because you're doing causal LM\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    data_collator=data_collator,  # üëà Add this line\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa984e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# just in case\u001b[39;00m\n\u001b[32m      6\u001b[39m torch.cuda.empty_cache()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m model.save_pretrained(\u001b[33m\"\u001b[39m\u001b[33m./starcoder_elm_finetuned_2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m tokenizer.save_pretrained(\u001b[33m\"\u001b[39m\u001b[33m./starcoder_elm_finetuned_2\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nelld\\Desktop\\N7\\2SNIA\\llamaenv\\Lib\\site-packages\\transformers\\trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nelld\\Desktop\\N7\\2SNIA\\llamaenv\\Lib\\site-packages\\transformers\\trainer.py:2565\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2559\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m   2560\u001b[39m     tr_loss_step = \u001b[38;5;28mself\u001b[39m.training_step(model, inputs, num_items_in_batch)\n\u001b[32m   2562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2563\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2564\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2566\u001b[39m ):\n\u001b[32m   2567\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2568\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n\u001b[32m   2569\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# just in case\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(\"./starcoder_elm_finetuned\")\n",
    "tokenizer.save_pretrained(\"./starcoder_elm_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bbcde19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nelld\\Desktop\\N7\\2SNIA\\llamaenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Completion de code\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Configurer un pipeline de g√©n√©ration\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m generator = pipeline(\u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m, model=\u001b[43mmodel\u001b[49m, tokenizer=tokenizer)\n\u001b[32m      8\u001b[39m prompt = \u001b[33m\"\u001b[39m\u001b[33mlistLength : List a -> Int\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mlistLength list =\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m results = generator(prompt, max_length=\u001b[32m50\u001b[39m, num_return_sequences=\u001b[32m3\u001b[39m, do_sample=\u001b[38;5;28;01mTrue\u001b[39;00m, temperature=\u001b[32m0.7\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Completion de code\n",
    "\n",
    "# Configurer un pipeline de g√©n√©ration\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "prompt = \"listLength : List a -> Int\\nlistLength list =\"\n",
    "results = generator(prompt, max_length=50, num_return_sequences=3, do_sample=True, temperature=0.7)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"--- G√©n√©ration {i+1} ---\")\n",
    "    print(result['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
